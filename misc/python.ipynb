{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "from transformers import BertModel, BertTokenizer, BertForMaskedLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path(os.environ[\"MASTER\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Das bedeutet: Er hat sehr viele schlimme Verletzungen.\"\n",
    "\n",
    "model= \"deepset/gbert-base\"\n",
    "tokenizer= BertTokenizer.from_pretrained(model)\n",
    "\n",
    "encoding = tokenizer.encode(s)\n",
    "tokens = tokenizer.tokenize(s)\n",
    "print(encoding)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import DatasetWordPiece\n",
    "from models.tvae_trainer import TVAETrainer\n",
    "from models.tvae_model import TVAE\n",
    "import torch\n",
    "\n",
    "dataset = DatasetWordPiece(large=False, max_length=128)\n",
    "model = TVAE(ntoken=dataset.vocab_size)\n",
    "trainer = TVAETrainer(dataset=dataset, model=model)\n",
    "\n",
    "# def f(s):\n",
    "#     mem = torch.cuda.memory_allocated()\n",
    "#     print(f\"{s}: {mem/(1024**2)} GiB ({mem} bytes)\")\n",
    "# f(\"Before\")\n",
    "# model.to(\"cuda\")\n",
    "# f(\"After model\")\n",
    "\n",
    "s = \"Das bedeutet: Er hat sehr viele schlimme Verletzungen.\"\n",
    "path_model = Path(\n",
    "    \"save/2023-01-18_Pin_down_Lr/checkpoints/2023-01-20_20:44:29_TVAE_German/2023-01-20_20:44:29_TVAE_RegTrue/model.pt\")\n",
    "\n",
    "model = TVAE(ntoken=dataset.vocab_size)\n",
    "model.load_state_dict(torch.load(path_model))\n",
    "model.cuda()\n",
    "\n",
    "t = torch.Tensor(dataset.encode(s))\n",
    "t = t.view(1, -1).long()\n",
    "lbl = torch.IntTensor([[1]])\n",
    "batch = trainer.process_batch_data((t, lbl))\n",
    "\n",
    "d = {}\n",
    "for i, k in enumerate([\"src\", \"tgt\", \"tgt_true\", \"tgt_mask\", \"memory_mask\", \"src_key_padding_mask\", \"tgt_key_padding_mask\", \"labels\"]):\n",
    "    d[k] = batch[i]\n",
    "\n",
    "output = model(\n",
    "    src=d[\"src\"],\n",
    "    tgt=d[\"tgt\"],\n",
    "    tgt_mask=d[\"tgt_mask\"],\n",
    "    memory_mask=d[\"memory_mask\"],\n",
    "    src_key_padding_mask=d[\"src_key_padding_mask\"],\n",
    "    tgt_key_padding_mask=d[\"tgt_key_padding_mask\"]\n",
    ")\n",
    "\n",
    "prob = output[0]\n",
    "out_tokens = torch.argmax(prob, dim=-1)\n",
    "out_tokens = [int(i) for i in list(out_tokens.data.to(\"cpu\")[0])]\n",
    "\n",
    "\n",
    "def acc(weights, targets):\n",
    "    # get predicted label\n",
    "    weights = torch.argmax(weights, dim=-1)\n",
    "    # remove [PAD] label (== 0) from accuracy calculation\n",
    "    mask = targets.ge(0.5)\n",
    "    numerator = torch.sum(targets.masked_select(\n",
    "        mask) == weights.masked_select(mask))\n",
    "    denominator = len(targets.masked_select(mask))\n",
    "    acc = numerator / denominator\n",
    "    return acc\n",
    "\n",
    "# print(dataset.tokenizer.decode(out_tokens))\n",
    "# print(acc(prob, d[\"tgt_true\"]))\n",
    "# print(list(d[\"tgt_true\"][0].cpu().numpy()))\n",
    "# print(out_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52a59b75e5ddc235e8ae75c6f232f2b835bf44cfac57e20d283db7df608e2c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
