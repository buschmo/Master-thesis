{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.datasets import DatasetWordPiece\n",
    "from models.tvae_trainer import TVAETrainer\n",
    "from models.tvae_model import TVAE\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "# Switch to correct folder\n",
    "try:\n",
    "    os.chdir(Path(os.environ[\"MASTER\"]))\n",
    "except KeyError:\n",
    "    os.chdir(Path(os.environ[\"HOME\"],\"repos/Master-thesis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \n",
    "\n",
    "model= \"deepset/gbert-base\"\n",
    "tokenizer= BertTokenizer.from_pretrained(model)\n",
    "\n",
    "encoding = tokenizer.encode(s)\n",
    "tokens = tokenizer.tokenize(s)\n",
    "print(encoding)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"save/2023-01-18_Pin_down_Lr/checkpoints/2023-01-20_20:44:29_TVAE_German/2023-01-20_20:44:29_TVAE_RegTrue/model.pt\": [\n",
    "        [\"Simple\",\"Das bedeutet: Er hat sehr viele schlimme Verletzungen.\"]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetWordPiece(large=False, max_length=128)\n",
    "trainer = TVAETrainer(dataset=dataset, model=model)\n",
    "model = TVAE(ntoken=dataset.vocab_size)\n",
    "model.cuda()\n",
    "\n",
    "fake_label = torch.IntTensor([[1]])\n",
    "\n",
    "for model, sents in settings.items():\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    for sent in sents:\n",
    "        t = torch.Tensor(dataset.encode(sent))\n",
    "        t = t.view(1, -1).long()\n",
    "        batch = trainer.process_batch_data((t, fake_label))\n",
    "\n",
    "        d = {}\n",
    "        for i, k in enumerate([\"src\", \"tgt\", \"tgt_true\", \"tgt_mask\", \"memory_mask\", \"src_key_padding_mask\", \"tgt_key_padding_mask\", \"labels\"]):\n",
    "            d[k] = batch[i]\n",
    "\n",
    "        output = model(\n",
    "            src=d[\"src\"],\n",
    "            tgt=d[\"tgt\"],\n",
    "            tgt_mask=d[\"tgt_mask\"],\n",
    "            memory_mask=d[\"memory_mask\"],\n",
    "            src_key_padding_mask=d[\"src_key_padding_mask\"],\n",
    "            tgt_key_padding_mask=d[\"tgt_key_padding_mask\"]\n",
    "        )\n",
    "\n",
    "        prob = output[0]\n",
    "        out_tokens = torch.argmax(prob, dim=-1)\n",
    "        out_tokens = [int(i) for i in list(out_tokens.data.to(\"cpu\")[0])]\n",
    "\n",
    "        print(dataset.tokenizer.decode(out_tokens))\n",
    "        print(acc(prob, d[\"tgt_true\"]))\n",
    "        print(list(d[\"tgt_true\"][0].cpu().numpy()))\n",
    "        print(out_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52a59b75e5ddc235e8ae75c6f232f2b835bf44cfac57e20d283db7df608e2c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
