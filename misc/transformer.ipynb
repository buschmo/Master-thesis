{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "from transformers import BertModel, BertTokenizer, BertForMaskedLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Dies ist ein Test, welcher ganz ok l√§uft.\",\n",
    "             \"Also geht es jetzt los.\", \"'Mein Vater', sagt er.\"]\n",
    "model_name = \"deepset/gbert-base\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "vocab_size = len(tokenizer.get_vocab())\n",
    "d_model = 256\n",
    "embedder = nn.Embedding(vocab_size, d_model)\n",
    "tokens = torch.IntTensor(\n",
    "    [tokenizer.encode(sent, padding=\"max_length\") for sent in sentences])\n",
    "max_sent_length = tokenizer.model_max_length\n",
    "\n",
    "print(tokenizer.decode([0, 1, 100, 101, 102, 103, 104]))\n",
    "\n",
    "tgt_mask = torch.triu(torch.ones(\n",
    "    max_sent_length-1, max_sent_length-1) * float('-inf'), diagonal=1)\n",
    "\n",
    "tgt = tokens[:, :-1].clone()\n",
    "tgt[tgt == 103] = 0\n",
    "tgt_key_padding_mask = (tgt == 0)\n",
    "src_key_padding_mask = (tokens == 0)\n",
    "\n",
    "tgt = embedder(tgt)\n",
    "src = embedder(tokens)\n",
    "tgt_true = embedder(tokens[:, 1:])\n",
    "\n",
    "encoder_layer = nn.TransformerEncoderLayer(\n",
    "    d_model=d_model, nhead=8, batch_first=True)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "decoder_layer = nn.TransformerDecoderLayer(\n",
    "    d_model=d_model, nhead=8, batch_first=True)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = transformer_encoder(src, src_key_padding_mask=src_key_padding_mask)\n",
    "memory_avg = torch.mean(memory, dim=1, keepdim=True)\n",
    "memory_avg_repeat = torch.mean(memory, dim=1, keepdim=True).repeat(1,511,1)\n",
    "memory_mask = torch.triu(torch.ones(\n",
    "    max_sent_length, max_sent_length) * float('-inf'), diagonal=1)[:-1]\n",
    "memory_avg_mask = torch.triu(torch.ones(\n",
    "    max_sent_length, max_sent_length) * float('-inf'), diagonal=1)[:-1,:1]\n",
    "memory_avg_repeat_mask = torch.triu(torch.ones(\n",
    "    max_sent_length-1, max_sent_length-1) * float('-inf'), diagonal=1)\n",
    "\n",
    "output = transformer_decoder(\n",
    "    tgt, memory, memory_mask=memory_mask, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "output_avg = transformer_decoder(\n",
    "    tgt, memory_avg, memory_mask=memory_avg_mask, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "output_avg_repeat = transformer_decoder(\n",
    "    tgt, memory_avg_repeat, memory_mask=memory_avg_repeat_mask, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "print(f\"src.shape: {src.shape}\")\n",
    "print(f\"tgt.shape: {tgt.shape}\")\n",
    "print(f\"memory.shape: {memory.shape}\")\n",
    "print(f\"memory_avg.shape: {memory_avg.shape}\")\n",
    "print(f\"output.shape: {output.shape}\")\n",
    "print(f\"output_avg.shape: {output_avg.shape}\")\n",
    "print(f\"output_avg_repeat.shape: {output_avg_repeat.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52a59b75e5ddc235e8ae75c6f232f2b835bf44cfac57e20d283db7df608e2c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
